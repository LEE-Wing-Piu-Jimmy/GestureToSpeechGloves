{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all needed lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of files into a 3D array of [samples, timesteps, features]\n",
    "def load_file(filepath):\n",
    "\tdataframe = pd.read_csv(filepath)\n",
    "\treturn dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hot': 0, 'I': 1, 'like': 2, 'weather': 3, 'you': 4}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs = os.listdir('./ready')\n",
    "d = dict(enumerate(dirs))\n",
    "d_swap = {v: k for k, v in d.items()}\n",
    "d_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 115, 30) (370,)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "dirs = os.listdir('./ready')\n",
    "maxtimestep = 0\n",
    "\n",
    "for dir in dirs:\n",
    "    files = os.listdir('./ready/'+dir)\n",
    "    for file in files:\n",
    "        loaded = load_file('./ready/'+dir+'/'+file)\n",
    "        # get the maximum time step shape for padding\n",
    "        if loaded.shape[0]>maxtimestep:\n",
    "            maxtimestep = loaded.shape[0]\n",
    "        \n",
    "        # remove the first(time index) and last column(nan)\n",
    "        loaded = loaded[:,1:-1]\n",
    "        x.append(loaded)\n",
    "        y.append(d_swap[dir])\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if len(x[i]) < maxtimestep:\n",
    "        difference = maxtimestep - len(x[i])\n",
    "        d1 = difference//2\n",
    "        d2 = difference - d1\n",
    "        x[i] = np.concatenate([np.zeros((d1,30)),x[i], np.zeros((d2,30))], axis=0)\n",
    "        \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "print(x.shape, y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 115, 30) (74, 115, 30) (296, 5) (74, 5)\n"
     ]
    }
   ],
   "source": [
    "# load data set and split into training and testing inputs (X) and outputs (y)\n",
    "\n",
    "# nornmalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "tran_x = []\n",
    "for i in range(len(x)):\n",
    "    scalar = scalar.fit(x[i])\n",
    "    tran_x.append(scalar.transform(x[i]))\n",
    "x = np.array(tran_x)\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(x,y, train_size=0.8, random_state=1111)\n",
    "trainy = keras.utils.to_categorical(trainy)\n",
    "testy = keras.utils.to_categorical(testy)\n",
    "print(trainX.shape, testX.shape, trainy.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model5(trainX, trainy, testX, testy):\n",
    "\tverbose, epochs, batch_size = 1, 10, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\t# model.add(keras.layers.LSTM(64, input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D(pool_size=3))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\t# Define the early stopping callback\n",
    "\tearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, validation_split=0.2, batch_size=batch_size, verbose=verbose, callbacks=[early_stop])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 23ms/step - loss: 0.6670 - accuracy: 0.7924 - val_loss: 0.1210 - val_accuracy: 0.9667\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0702 - accuracy: 0.9831 - val_loss: 0.0286 - val_accuracy: 0.9833\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.0478e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = train_model5(trainX,trainy,testX,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 113, 64)           5824      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 113, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 37, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2368)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               236900    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 505       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,229\n",
      "Trainable params: 243,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./assets\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 115, 30) (74, 5)\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009110916405916214, 1.0]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating test set\n",
    "print(testX.shape,testy.shape)\n",
    "model.evaluate(testX, testy, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
